{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# for nlp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "# for stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "# for Lemmatizing\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizing = WordNetLemmatizer()\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for machine learning\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "# save and load models\n",
    "import pickle\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>dysfunctional selfish drags kids dysfunction #run</td>\n",
       "      <td>run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks #lyft credit cause offer wheelchair van...</td>\n",
       "      <td>lyft  disapointed  getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>majesty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "      <td>motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  dysfunctional selfish drags kids dysfunction #run   \n",
       "1  thanks #lyft credit cause offer wheelchair van...   \n",
       "2                                            majesty   \n",
       "3                                             #model   \n",
       "4                     factsguide society #motivation   \n",
       "\n",
       "                          hashtag  word_count  char_count  avg_word  \\\n",
       "0                             run          21         102  4.555556   \n",
       "1   lyft  disapointed  getthanked          22         122  5.315789   \n",
       "2                             NaN           5          21  5.666667   \n",
       "3                           model          17          86  4.928571   \n",
       "4                      motivation           8          39  8.000000   \n",
       "\n",
       "   stopwords  hashtags  \n",
       "0         10         1  \n",
       "1          5         3  \n",
       "2          1         0  \n",
       "3          5         1  \n",
       "4          1         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"assets/data/data_analyzed_df.csv\")\n",
    "del df['Unnamed: 0']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          49159 non-null  int64  \n",
      " 1   label       31962 non-null  float64\n",
      " 2   tweet       49159 non-null  object \n",
      " 3   tidy_tweet  48810 non-null  object \n",
      " 4   hashtag     35894 non-null  object \n",
      " 5   word_count  49159 non-null  int64  \n",
      " 6   char_count  49159 non-null  int64  \n",
      " 7   avg_word    49159 non-null  float64\n",
      " 8   stopwords   49159 non-null  int64  \n",
      " 9   hashtags    49159 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[0:31962]\n",
    "test_df = df[31962:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>dysfunctional selfish drags kids dysfunction #run</td>\n",
       "      <td>run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[dysfunctional, selfish, drags, kids, dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks #lyft credit cause offer wheelchair van...</td>\n",
       "      <td>lyft  disapointed  getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[thanks, #, lyft, credit, cause, offer, wheelc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>majesty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[#, model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "      <td>motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[factsguide, society, #, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  dysfunctional selfish drags kids dysfunction #run   \n",
       "1  thanks #lyft credit cause offer wheelchair van...   \n",
       "2                                            majesty   \n",
       "3                                             #model   \n",
       "4                     factsguide society #motivation   \n",
       "\n",
       "                          hashtag  word_count  char_count  avg_word  \\\n",
       "0                             run          21         102  4.555556   \n",
       "1   lyft  disapointed  getthanked          22         122  5.315789   \n",
       "2                             NaN           5          21  5.666667   \n",
       "3                           model          17          86  4.928571   \n",
       "4                      motivation           8          39  8.000000   \n",
       "\n",
       "   stopwords  hashtags                                              token  \n",
       "0         10         1  [dysfunctional, selfish, drags, kids, dysfunct...  \n",
       "1          5         3  [thanks, #, lyft, credit, cause, offer, wheelc...  \n",
       "2          1         0                                          [majesty]  \n",
       "3          5         1                                         [#, model]  \n",
       "4          1         1               [factsguide, society, #, motivation]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[train_df['tidy_tweet'].notna()] \n",
    "train_df['token'] = train_df['tidy_tweet'].apply(lambda x: word_tokenize(x))\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>dysfunctional selfish drags kids dysfunction #run</td>\n",
       "      <td>run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[dysfunctional, selfish, drags, kids, dysfunct...</td>\n",
       "      <td>dysfunct selfish drag kid dysfunct # run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks #lyft credit cause offer wheelchair van...</td>\n",
       "      <td>lyft  disapointed  getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[thanks, #, lyft, credit, cause, offer, wheelc...</td>\n",
       "      <td>thank # lyft credit caus offer wheelchair van ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>majesty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[majesty]</td>\n",
       "      <td>majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[#, model]</td>\n",
       "      <td># model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "      <td>motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[factsguide, society, #, motivation]</td>\n",
       "      <td>factsguid societi # motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  dysfunctional selfish drags kids dysfunction #run   \n",
       "1  thanks #lyft credit cause offer wheelchair van...   \n",
       "2                                            majesty   \n",
       "3                                             #model   \n",
       "4                     factsguide society #motivation   \n",
       "\n",
       "                          hashtag  word_count  char_count  avg_word  \\\n",
       "0                             run          21         102  4.555556   \n",
       "1   lyft  disapointed  getthanked          22         122  5.315789   \n",
       "2                             NaN           5          21  5.666667   \n",
       "3                           model          17          86  4.928571   \n",
       "4                      motivation           8          39  8.000000   \n",
       "\n",
       "   stopwords  hashtags                                              token  \\\n",
       "0         10         1  [dysfunctional, selfish, drags, kids, dysfunct...   \n",
       "1          5         3  [thanks, #, lyft, credit, cause, offer, wheelc...   \n",
       "2          1         0                                          [majesty]   \n",
       "3          5         1                                         [#, model]   \n",
       "4          1         1               [factsguide, society, #, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \n",
       "0           dysfunct selfish drag kid dysfunct # run  \n",
       "1  thank # lyft credit caus offer wheelchair van ...  \n",
       "2                                            majesti  \n",
       "3                                            # model  \n",
       "4                          factsguid societi # motiv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tweet_stemmed'] = train_df['token'].apply(lambda x: ' '.join([stemming.stem(i) for i in x]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>dysfunctional selfish drags kids dysfunction #run</td>\n",
       "      <td>run</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[dysfunctional, selfish, drags, kids, dysfunct...</td>\n",
       "      <td>dysfunct selfish drag kid dysfunct # run</td>\n",
       "      <td>dysfunctional selfish drag kid dysfunction # run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks #lyft credit cause offer wheelchair van...</td>\n",
       "      <td>lyft  disapointed  getthanked</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[thanks, #, lyft, credit, cause, offer, wheelc...</td>\n",
       "      <td>thank # lyft credit caus offer wheelchair van ...</td>\n",
       "      <td>thanks # lyft credit cause offer wheelchair va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>majesty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[majesty]</td>\n",
       "      <td>majesti</td>\n",
       "      <td>majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model</td>\n",
       "      <td>model</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[#, model]</td>\n",
       "      <td># model</td>\n",
       "      <td># model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "      <td>motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[factsguide, society, #, motivation]</td>\n",
       "      <td>factsguid societi # motiv</td>\n",
       "      <td>factsguide society # motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0  dysfunctional selfish drags kids dysfunction #run   \n",
       "1  thanks #lyft credit cause offer wheelchair van...   \n",
       "2                                            majesty   \n",
       "3                                             #model   \n",
       "4                     factsguide society #motivation   \n",
       "\n",
       "                          hashtag  word_count  char_count  avg_word  \\\n",
       "0                             run          21         102  4.555556   \n",
       "1   lyft  disapointed  getthanked          22         122  5.315789   \n",
       "2                             NaN           5          21  5.666667   \n",
       "3                           model          17          86  4.928571   \n",
       "4                      motivation           8          39  8.000000   \n",
       "\n",
       "   stopwords  hashtags                                              token  \\\n",
       "0         10         1  [dysfunctional, selfish, drags, kids, dysfunct...   \n",
       "1          5         3  [thanks, #, lyft, credit, cause, offer, wheelc...   \n",
       "2          1         0                                          [majesty]   \n",
       "3          5         1                                         [#, model]   \n",
       "4          1         1               [factsguide, society, #, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0           dysfunct selfish drag kid dysfunct # run   \n",
       "1  thank # lyft credit caus offer wheelchair van ...   \n",
       "2                                            majesti   \n",
       "3                                            # model   \n",
       "4                          factsguid societi # motiv   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0   dysfunctional selfish drag kid dysfunction # run  \n",
       "1  thanks # lyft credit cause offer wheelchair va...  \n",
       "2                                            majesty  \n",
       "3                                            # model  \n",
       "4                    factsguide society # motivation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tweet_lemmatized'] = train_df['token'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag Of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "bow_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31751x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 105529 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbow_stem = bow_vectorizer.fit_transform(train_df['tweet_stemmed'])\n",
    "trainbow_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31751x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 95453 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbow_lemm = bow_vectorizer.fit_transform(train_df['tweet_lemmatized'])\n",
    "trainbow_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=1000, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintfidf_stem = tfidf_vectorizer.fit_transform(train_df['tweet_stemmed'])\n",
    "traintfidf_stem.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31751, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintfidf_stem.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintfidf_lemm = tfidf_vectorizer.fit_transform(train_df['tweet_lemmatized'])\n",
    "traintfidf_lemm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31963</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists everyone #birds #movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "31962  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963  31964   @user #white #supremacists want everyone to s...   \n",
       "\n",
       "                                              tidy_tweet  \n",
       "31962  #studiolife #aislife #requires #passion #dedic...  \n",
       "31963        #white #supremacists everyone #birds #movie  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection of few columns\n",
    "test_df = test_df[['id','tweet','tidy_tweet']]\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['tidy_tweet'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>[#, studiolife, #, aislife, #, requires, #, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31963</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists everyone #birds #movie</td>\n",
       "      <td>[#, white, #, supremacists, everyone, #, birds...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "31962  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963  31964   @user #white #supremacists want everyone to s...   \n",
       "\n",
       "                                              tidy_tweet  \\\n",
       "31962  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963        #white #supremacists everyone #birds #movie   \n",
       "\n",
       "                                                   token  \n",
       "31962  [#, studiolife, #, aislife, #, requires, #, pa...  \n",
       "31963  [#, white, #, supremacists, everyone, #, birds...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['token'] = test_df['tidy_tweet'].apply(lambda x: word_tokenize(x))\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>[#, studiolife, #, aislife, #, requires, #, pa...</td>\n",
       "      <td># studiolif # aislif # requir # passion # dedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31963</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists everyone #birds #movie</td>\n",
       "      <td>[#, white, #, supremacists, everyone, #, birds...</td>\n",
       "      <td># white # supremacist everyon # bird # movi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "31962  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963  31964   @user #white #supremacists want everyone to s...   \n",
       "\n",
       "                                              tidy_tweet  \\\n",
       "31962  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963        #white #supremacists everyone #birds #movie   \n",
       "\n",
       "                                                   token  \\\n",
       "31962  [#, studiolife, #, aislife, #, requires, #, pa...   \n",
       "31963  [#, white, #, supremacists, everyone, #, birds...   \n",
       "\n",
       "                                           tweet_stemmed  \n",
       "31962  # studiolif # aislif # requir # passion # dedi...  \n",
       "31963        # white # supremacist everyon # bird # movi  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['tweet_stemmed'] = test_df['token'].apply(lambda x: ' '.join([stemming.stem(i) for i in x]))\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbow_stem = bow_vectorizer.fit_transform(test_df['tweet_stemmed'])\n",
    "testbow_stem.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>[#, studiolife, #, aislife, #, requires, #, pa...</td>\n",
       "      <td># studiolif # aislif # requir # passion # dedi...</td>\n",
       "      <td># studiolife # aislife # requires # passion # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31963</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists everyone #birds #movie</td>\n",
       "      <td>[#, white, #, supremacists, everyone, #, birds...</td>\n",
       "      <td># white # supremacist everyon # bird # movi</td>\n",
       "      <td># white # supremacist everyone # bird # movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "31962  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963  31964   @user #white #supremacists want everyone to s...   \n",
       "\n",
       "                                              tidy_tweet  \\\n",
       "31962  #studiolife #aislife #requires #passion #dedic...   \n",
       "31963        #white #supremacists everyone #birds #movie   \n",
       "\n",
       "                                                   token  \\\n",
       "31962  [#, studiolife, #, aislife, #, requires, #, pa...   \n",
       "31963  [#, white, #, supremacists, everyone, #, birds...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "31962  # studiolif # aislif # requir # passion # dedi...   \n",
       "31963        # white # supremacist everyon # bird # movi   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "31962  # studiolife # aislife # requires # passion # ...  \n",
       "31963      # white # supremacist everyone # bird # movie  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['tweet_lemmatized'] = test_df['token'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbow_lemm = bow_vectorizer.fit_transform(test_df['tweet_lemmatized'])\n",
    "testbow_lemm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "testtfidf_stem = tfidf_vectorizer.fit_transform(test_df['tweet_stemmed'])\n",
    "testtfidf_lemm = tfidf_vectorizer.fit_transform(test_df['tweet_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/data/tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tfidf_vectorizer,'assets/data/tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=traintfidf_lemm #x: predictors\n",
    "y=train_df['label'] #y: label\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression() # for lemmatized data\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr=lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9454125551123241\n",
      "f1 score : 0.41704035874439455\n",
      "[[8820  480]\n",
      " [  40  186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97      9300\n",
      "         1.0       0.28      0.82      0.42       226\n",
      "\n",
      "    accuracy                           0.95      9526\n",
      "   macro avg       0.64      0.89      0.69      9526\n",
      "weighted avg       0.98      0.95      0.96      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score :\", accuracy_score(predict_lr,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_lr,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_lr,ytest))\n",
    "print(classification_report(predict_lr,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is very low for hate label due to less sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=traintfidf_stem # for stemmed data\n",
    "y1=train_df['label']\n",
    "x1train,x1test,y1train,y1test=train_test_split(X1,y1,test_size=.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1=LogisticRegression()\n",
    "lr1.fit(x1train,y1train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr1=lr1.predict(x1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9460424102456435\n",
      "f1 score : 0.4237668161434977\n",
      "[[8823  477]\n",
      " [  37  189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97      9300\n",
      "         1.0       0.28      0.84      0.42       226\n",
      "\n",
      "    accuracy                           0.95      9526\n",
      "   macro avg       0.64      0.89      0.70      9526\n",
      "weighted avg       0.98      0.95      0.96      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_lr1,y1test))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_lr1,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_lr1,y1test))\n",
    "print(classification_report(predict_lr1,y1test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar performance to lemmatization preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.949086710056687\n",
      "f1 score : 0.46408839779005523\n",
      "[[8831  456]\n",
      " [  29  210]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97      9287\n",
      "         1.0       0.32      0.88      0.46       239\n",
      "\n",
      "    accuracy                           0.95      9526\n",
      "   macro avg       0.66      0.91      0.72      9526\n",
      "weighted avg       0.98      0.95      0.96      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC()\n",
    "svc.fit(xtrain,ytrain)\n",
    "predict_svc=svc.predict(xtest)\n",
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_svc,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_svc,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_svc,ytest))\n",
    "print(classification_report(predict_svc,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.588074742809154\n",
      "f1 score : 0.2293794186959937\n",
      "[[5018   82]\n",
      " [3842  584]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.98      0.72      5100\n",
      "         1.0       0.88      0.13      0.23      4426\n",
      "\n",
      "    accuracy                           0.59      9526\n",
      "   macro avg       0.72      0.56      0.47      9526\n",
      "weighted avg       0.71      0.59      0.49      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb=GaussianNB()\n",
    "nb.fit(xtrain.toarray(),ytrain)\n",
    "predict_nb=nb.predict(xtest.toarray())\n",
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_nb,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_nb,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_nb,ytest))\n",
    "print(classification_report(predict_nb,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9441528448456855\n",
      "f1 score : 0.3770491803278688\n",
      "[[8833  505]\n",
      " [  27  161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97      9338\n",
      "         1.0       0.24      0.86      0.38       188\n",
      "\n",
      "    accuracy                           0.94      9526\n",
      "   macro avg       0.62      0.90      0.67      9526\n",
      "weighted avg       0.98      0.94      0.96      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlnb = MultinomialNB()\n",
    "mlnb.fit(xtrain.toarray(),ytrain)\n",
    "predict_mlnb=mlnb.predict(xtest.toarray())\n",
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_mlnb,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_mlnb,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_mlnb,ytest))\n",
    "print(classification_report(predict_mlnb,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9461473861011968\n",
      "f1 score : 0.5448092280390417\n",
      "[[8706  359]\n",
      " [ 154  307]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97      9065\n",
      "         1.0       0.46      0.67      0.54       461\n",
      "\n",
      "    accuracy                           0.95      9526\n",
      "   macro avg       0.72      0.81      0.76      9526\n",
      "weighted avg       0.96      0.95      0.95      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(xtrain.toarray(),ytrain)\n",
    "predict_dt = dt.predict(xtest.toarray())\n",
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_dt,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_dt,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_dt,ytest))\n",
    "print(classification_report(predict_dt,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.952865840856603\n",
      "f1 score : 0.5645004849660523\n",
      "[[8786  375]\n",
      " [  74  291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98      9161\n",
      "         1.0       0.44      0.80      0.56       365\n",
      "\n",
      "    accuracy                           0.95      9526\n",
      "   macro avg       0.71      0.88      0.77      9526\n",
      "weighted avg       0.97      0.95      0.96      9526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(xtrain.toarray(),ytrain) # you can test with grid search methodology\n",
    "predict_rf = rf.predict(xtest.toarray())\n",
    "# accuracy score\n",
    "print(\"accuracy score :\", accuracy_score(predict_rf,ytest))\n",
    "\n",
    "# calculating the f1 score for the validation set\n",
    "print(\"f1 score :\", f1_score(predict_rf,ytest))\n",
    "\n",
    "print(confusion_matrix(predict_rf,ytest))\n",
    "print(classification_report(predict_rf,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/data/random_forest.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf,'assets/model/random_forest.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "763e2884bc3b6e7a40d218995b9d96d1e5ad824574033f07f5a58e539fc19e77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('full_stack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
